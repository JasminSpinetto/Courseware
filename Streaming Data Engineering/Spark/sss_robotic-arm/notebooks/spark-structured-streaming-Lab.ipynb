{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Structured Streaming - Demo\n",
    "## Robotic Arm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://071a78ba2846:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>test</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f9bdafc4430>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.streaming import StreamingContext\n",
    "import io\n",
    "from pyspark.sql.functions import *\n",
    "import time\n",
    "import json\n",
    "import struct\n",
    "import requests \n",
    "\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.0.1,org.apache.spark:spark-streaming-kafka-0-10_2.11:2.4.5,org.apache.kafka:kafka-clients:2.6.0 pyspark-shell'\n",
    "                                    \n",
    "spark = (SparkSession.builder \n",
    "    .master(\"local[*]\")\n",
    "    .appName(\"test\")\n",
    "    .getOrCreate()\n",
    "        )\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set up the environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = 'RoboticArm'\n",
    "servers = \"kafka:9092\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers in Spark Structured Streaming \n",
    "\n",
    "Please refer to [epl_robotic-arm/readme.md](https://github.com/emanueledellavalle/streaming-data-analytics/tree/main/codes/epl_robotic-arm/readme.md) for the EPL version of the following queries.\n",
    "\n",
    "Let's first try with the model proposed for EPL and see what happens. To get the data run [datagen1.ipynb](datagen1.ipynb)\n",
    "\n",
    "### Let's create the streaming Data Frames using the data in the kafka topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "roboticArm_schema = StructType([\n",
    "    StructField(\"id\", StringType(), True),\n",
    "    StructField(\"status\", StringType(), True),\n",
    "    StructField(\"stressLevel\", IntegerType(), True),\n",
    "    StructField(\"ts\", TimestampType(), True)])\n",
    "\n",
    "raw_roboticArm_df = (spark\n",
    "  .readStream\n",
    "  .format(\"kafka\")\n",
    "  .option(\"kafka.bootstrap.servers\", servers)\n",
    "  .option(\"startingOffsets\", \"earliest\")\n",
    "  .option(\"subscribe\", topic)\n",
    "  .load())\n",
    "\n",
    "roboticArm_sdf = (raw_roboticArm_df\n",
    "                      .select(from_json(col(\"value\").cast(\"string\"), roboticArm_schema).alias(\"value\"))\n",
    "                      .select(\"value.*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- stressLevel: integer (nullable = true)\n",
      " |-- ts: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "roboticArm_sdf.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to make sure that it works, let's first inspect the content of the stream "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_query = (roboticArm_sdf\n",
    "    .writeStream\n",
    "    .format(\"memory\") # this is for debug purpose only! DO NOT USE IN PRODUCTION\n",
    "    .queryName(\"sinkTable\")\n",
    "    .start())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run the following cell to see the most recent content of the sinkTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+-----------+-------------------+\n",
      "| id|     status|stressLevel|                 ts|\n",
      "+---+-----------+-----------+-------------------+\n",
      "|  2|placingGood|          3|2022-11-01 14:59:01|\n",
      "|  1|placingGood|          3|2022-11-01 14:59:01|\n",
      "|  2| movingGood|          9|2022-11-01 14:58:51|\n",
      "|  2|goodGrasped|          5|2022-11-01 14:58:50|\n",
      "|  1| movingGood|          7|2022-11-01 14:58:48|\n",
      "+---+-----------+-----------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM sinkTable ORDER BY TS DESC\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "do not forget to stop queries that you are not using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_query.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E1\n",
    "\n",
    "> Propose how to model the streaming data generated by the robotic arms.\n",
    "\n",
    "Let's first try with the model proposed for EPL and see what happens. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E2\n",
    "\n",
    "> Write a continuous query that emits the max stress for each arm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the SQL sytyle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a logic table on top of the streaming data frame\n",
    "roboticArm_sdf.createTempView(\"RoboticArm\") # this time we will not clean it up, because we use it in the next queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_string = \"\"\"\n",
    "SELECT id, max(stressLevel) \n",
    "FROM RoboticArm \n",
    "GROUP BY id;\n",
    "\"\"\"\n",
    "\n",
    "# write your query in SQL, register it and start it\n",
    "e2 = (spark.sql(query_string)\n",
    "                     .writeStream\n",
    "                     .format(\"memory\")\n",
    "                     .outputMode(\"complete\") \n",
    "                     .queryName(\"sinkTable\")\n",
    "                     .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+\n",
      "| id|max(stressLevel)|\n",
      "+---+----------------+\n",
      "|  1|               7|\n",
      "|  2|               9|\n",
      "+---+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# look up the most recent results\n",
    "spark.sql(\"SELECT * FROM sinkTable\").show(5) # woithout ORDER BY TS DESC because the result in the table is already only the most recent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up\n",
    "e2.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The DataFrame style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your query in SQL, register it and start it\n",
    "e2bis = (roboticArm_sdf\n",
    "                     .groupBy(\"id\")\n",
    "                     .max()\n",
    "                     .writeStream\n",
    "                     .format(\"memory\")\n",
    "                     .outputMode(\"complete\")  \n",
    "                     .queryName(\"sinkTable\")\n",
    "                     .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+\n",
      "| id|max(stressLevel)|\n",
      "+---+----------------+\n",
      "|  1|               7|\n",
      "|  2|               9|\n",
      "+---+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# look up the most recent results\n",
    "spark.sql(\"SELECT * FROM sinkTable\").show(5) # woithout ORDER BY TS DESC because the result in the table is already only the most recent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up\n",
    "e2bis.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E3\n",
    "\n",
    "> A continuous query that emits the average stress level between a pick (status==goodGrasped) and a place (status==placingGood)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark Structured Streaming does not support the EPL's operator `->` (that reads as *followed by*. We need to use a stream-to-stream join.\n",
    "\n",
    "this is an hard task, let's simplify it\n",
    "\n",
    "### E3.1\n",
    "\n",
    "> A continuous query that emits the events between a moving (status==movingGood) and a place (status==placingGood)\n",
    "\n",
    "NOTE: no request to average and only two consecutive events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a streaming DataFrame with only event wher status='movingGood'\n",
    "moving_sdf = (roboticArm_sdf\n",
    "                .where(\"status='movingGood'\")\n",
    "                .withColumnRenamed(\"id\",\"idMoving\")\n",
    "                .withColumnRenamed(\"ts\",\"tsMoving\")\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a streaming DataFrame with only event wher status='placingGood'\n",
    "\n",
    "placing_sdf = (roboticArm_sdf\n",
    "                .where(\"status='placingGood'\")\n",
    "                .withColumnRenamed(\"id\",\"idPlacing\")\n",
    "                .withColumnRenamed(\"ts\",\"tsPlacing\")\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join without the event-time constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_sdf = (moving_sdf.join(\n",
    "  placing_sdf, expr(\"\"\"\n",
    "    (idMoving == idPlacing) AND\n",
    "    (tsMoving < tsPlacing )\n",
    "    \"\"\"\n",
    "    )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "e3 = (join_sdf\n",
    "                     .writeStream\n",
    "                     .format(\"memory\")\n",
    "                     .queryName(\"sinkTable\")\n",
    "                     .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----------+-------------------+---------+-----------+-----------+-------------------+\n",
      "|idMoving|status    |stressLevel|tsMoving           |idPlacing|status     |stressLevel|tsPlacing          |\n",
      "+--------+----------+-----------+-------------------+---------+-----------+-----------+-------------------+\n",
      "|1       |movingGood|7          |2022-11-01 14:59:21|1        |placingGood|3          |2022-11-01 15:00:07|\n",
      "|1       |movingGood|7          |2022-11-01 14:58:15|1        |placingGood|3          |2022-11-01 15:00:07|\n",
      "|1       |movingGood|7          |2022-11-01 14:58:48|1        |placingGood|3          |2022-11-01 15:00:07|\n",
      "|1       |movingGood|7          |2022-11-01 14:57:08|1        |placingGood|3          |2022-11-01 15:00:07|\n",
      "|1       |movingGood|7          |2022-11-01 14:57:41|1        |placingGood|3          |2022-11-01 15:00:07|\n",
      "+--------+----------+-----------+-------------------+---------+-----------+-----------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM sinkTable ORDER BY tsPlacing DESC\").show(5,False) # note, I change ts in tsPlacing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion\n",
    "\n",
    "Is this what we want?\n",
    "\n",
    "Let's try to count how many joins we have here ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+--------+\n",
      "|idPlacing|tsPlacing          |count(1)|\n",
      "+---------+-------------------+--------+\n",
      "|1        |2022-11-01 15:00:40|7       |\n",
      "|2        |2022-11-01 15:00:40|7       |\n",
      "|2        |2022-11-01 15:00:07|6       |\n",
      "|1        |2022-11-01 15:00:07|6       |\n",
      "|1        |2022-11-01 14:59:34|5       |\n",
      "|2        |2022-11-01 14:59:34|5       |\n",
      "|2        |2022-11-01 14:59:01|4       |\n",
      "|1        |2022-11-01 14:59:01|4       |\n",
      "|2        |2022-11-01 14:58:28|3       |\n",
      "|1        |2022-11-01 14:58:28|3       |\n",
      "|1        |2022-11-01 14:57:54|2       |\n",
      "|2        |2022-11-01 14:57:54|2       |\n",
      "|1        |2022-11-01 14:57:21|1       |\n",
      "|2        |2022-11-01 14:57:21|1       |\n",
      "+---------+-------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT idPlacing, tsPlacing, count(*) FROM sinkTable group by idPlacing, tsPlacing ORDER BY tsPlacing DESC\").show(20,False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Far too many!** ... and growing :-(\n",
    "\n",
    "O-: !!! ... and also **the state is growing** !!! :-O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"b532ef1d-18f1-486a-90c4-6c9a73a8ac8c\",\n",
      "    \"runId\": \"bbd5167e-d221-459a-903d-18be9c1bee5c\",\n",
      "    \"name\": \"sinkTable\",\n",
      "    \"timestamp\": \"2022-11-01T15:00:55.385Z\",\n",
      "    \"batchId\": 2,\n",
      "    \"numInputRows\": 8,\n",
      "    \"inputRowsPerSecond\": 0.6814890535820768,\n",
      "    \"processedRowsPerSecond\": 0.6848728704734184,\n",
      "    \"durationMs\": {\n",
      "        \"addBatch\": 11493,\n",
      "        \"getBatch\": 0,\n",
      "        \"latestOffset\": 2,\n",
      "        \"queryPlanning\": 96,\n",
      "        \"triggerExecution\": 11681,\n",
      "        \"walCommit\": 21\n",
      "    },\n",
      "    \"stateOperators\": [\n",
      "        {\n",
      "            \"numRowsTotal\": 28,\n",
      "            \"numRowsUpdated\": 0,\n",
      "            \"memoryUsedBytes\": 329664,\n",
      "            \"customMetrics\": {\n",
      "                \"loadedMapCacheHitCount\": 800,\n",
      "                \"loadedMapCacheMissCount\": 0,\n",
      "                \"stateOnCurrentVersionSizeBytes\": 42624\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"sources\": [\n",
      "        {\n",
      "            \"description\": \"KafkaV2[Subscribe[RoboticArm]]\",\n",
      "            \"startOffset\": {\n",
      "                \"RoboticArm\": {\n",
      "                    \"0\": 80\n",
      "                }\n",
      "            },\n",
      "            \"endOffset\": {\n",
      "                \"RoboticArm\": {\n",
      "                    \"0\": 84\n",
      "                }\n",
      "            },\n",
      "            \"numInputRows\": 8,\n",
      "            \"inputRowsPerSecond\": 0.6814890535820768,\n",
      "            \"processedRowsPerSecond\": 0.6848728704734184\n",
      "        }\n",
      "    ],\n",
      "    \"sink\": {\n",
      "        \"description\": \"MemorySink\",\n",
      "        \"numOutputRows\": 0\n",
      "    }\n",
      "}\n",
      "{'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-318287e46966>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlastProgress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import json\n",
    "while True:\n",
    "    print(json.dumps(e3.lastProgress, indent=4))\n",
    "    print(e3.status)\n",
    "    time.sleep(1)\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monitor for a minute the field `\"numRowsTotal\"` in `\"stateOperators\"`.\n",
    "\n",
    "**We need to add watermarks and a time constraint for state cleanup!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "e3.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "movingW_sdf = (roboticArm_sdf\n",
    "                .withWatermark(\"ts\",\"1 minute\") # WATERMARK ADDED HERE\n",
    "                .where(\"status='movingGood'\")\n",
    "                .withColumnRenamed(\"id\",\"idMoving\")\n",
    "                .withColumnRenamed(\"ts\",\"tsMoving\")\n",
    "               )\n",
    "\n",
    "placingW_sdf = (roboticArm_sdf\n",
    "                .withWatermark(\"ts\",\"1 minute\") # WATERMARK ADDED HERE\n",
    "                .where(\"status='placingGood'\")\n",
    "                .withColumnRenamed(\"id\",\"idPlacing\")\n",
    "                .withColumnRenamed(\"ts\",\"tsPlacing\")\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "joinTC_sdf = (movingW_sdf.join(\n",
    "  placingW_sdf, expr(\"\"\"\n",
    "    (idMoving == idPlacing) AND\n",
    "    (tsPlacing > tsMoving ) AND\n",
    "    (tsPlacing < tsMoving + interval 14 seconds )\"\"\" # TIME CONSTRAIN ADDED HERE (considering also that the time flows at half of the speed) !!!\n",
    "    )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "e3TC = (joinTC_sdf\n",
    "                     .writeStream\n",
    "                     .format(\"memory\")\n",
    "                     .queryName(\"sinkTable\")\n",
    "                     .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+--------+\n",
      "|idPlacing|tsPlacing          |count(1)|\n",
      "+---------+-------------------+--------+\n",
      "|2        |2022-11-01 15:03:59|1       |\n",
      "|1        |2022-11-01 15:03:59|1       |\n",
      "|1        |2022-11-01 15:03:26|1       |\n",
      "|2        |2022-11-01 15:03:26|1       |\n",
      "|1        |2022-11-01 15:02:53|1       |\n",
      "|2        |2022-11-01 15:02:53|1       |\n",
      "|1        |2022-11-01 15:02:20|1       |\n",
      "|2        |2022-11-01 15:02:20|1       |\n",
      "|1        |2022-11-01 15:01:46|1       |\n",
      "|2        |2022-11-01 15:01:46|1       |\n",
      "|2        |2022-11-01 15:01:13|1       |\n",
      "|1        |2022-11-01 15:01:13|1       |\n",
      "|2        |2022-11-01 15:00:40|1       |\n",
      "|1        |2022-11-01 15:00:40|1       |\n",
      "|2        |2022-11-01 15:00:07|1       |\n",
      "|1        |2022-11-01 15:00:07|1       |\n",
      "|2        |2022-11-01 14:59:34|1       |\n",
      "|1        |2022-11-01 14:59:34|1       |\n",
      "|2        |2022-11-01 14:59:01|1       |\n",
      "|1        |2022-11-01 14:59:01|1       |\n",
      "+---------+-------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT idPlacing, tsPlacing, count(*) FROM sinkTable group by idPlacing, tsPlacing ORDER BY tsPlacing DESC\").show(20,False) # note, I change ts in tsTemp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "also notice that the state no longer grows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"803e7cd9-c57d-4cca-98ab-515cd3c6caf0\",\n",
      "    \"runId\": \"f97bff0f-20ac-4823-8d90-312fc55d83fb\",\n",
      "    \"name\": \"sinkTable\",\n",
      "    \"timestamp\": \"2022-11-01T15:05:21.022Z\",\n",
      "    \"batchId\": 4,\n",
      "    \"numInputRows\": 8,\n",
      "    \"inputRowsPerSecond\": 0.6559527714004592,\n",
      "    \"processedRowsPerSecond\": 0.6537015852263443,\n",
      "    \"durationMs\": {\n",
      "        \"addBatch\": 12071,\n",
      "        \"getBatch\": 0,\n",
      "        \"latestOffset\": 3,\n",
      "        \"queryPlanning\": 121,\n",
      "        \"triggerExecution\": 12238,\n",
      "        \"walCommit\": 20\n",
      "    },\n",
      "    \"eventTime\": {\n",
      "        \"watermark\": \"2022-11-01T15:03:55.000Z\"\n",
      "    },\n",
      "    \"stateOperators\": [\n",
      "        {\n",
      "            \"numRowsTotal\": 12,\n",
      "            \"numRowsUpdated\": 0,\n",
      "            \"memoryUsedBytes\": 331072,\n",
      "            \"customMetrics\": {\n",
      "                \"loadedMapCacheHitCount\": 1600,\n",
      "                \"loadedMapCacheMissCount\": 0,\n",
      "                \"stateOnCurrentVersionSizeBytes\": 38400\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"sources\": [\n",
      "        {\n",
      "            \"description\": \"KafkaV2[Subscribe[RoboticArm]]\",\n",
      "            \"startOffset\": {\n",
      "                \"RoboticArm\": {\n",
      "                    \"0\": 176\n",
      "                }\n",
      "            },\n",
      "            \"endOffset\": {\n",
      "                \"RoboticArm\": {\n",
      "                    \"0\": 180\n",
      "                }\n",
      "            },\n",
      "            \"numInputRows\": 8,\n",
      "            \"inputRowsPerSecond\": 0.6559527714004592,\n",
      "            \"processedRowsPerSecond\": 0.6537015852263443\n",
      "        }\n",
      "    ],\n",
      "    \"sink\": {\n",
      "        \"description\": \"MemorySink\",\n",
      "        \"numOutputRows\": 0\n",
      "    }\n",
      "}\n",
      "{'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-45ff73b5502d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me3TC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlastProgress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me3TC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import json\n",
    "while True:\n",
    "    print(json.dumps(e3TC.lastProgress, indent=4))\n",
    "    print(e3TC.status)\n",
    "    time.sleep(1)\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "e3TC.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How much should the watermark and the time constraint be?**\n",
    "\n",
    "|watermark | time constraint | number of results per arm |reason                                         |\n",
    "|----------|-----------------|-------------------|-----------------------------------------------|\n",
    "|  any     |           <=10  |         0         | for each arm, there is no placing within less than 10 sec to a moving |   \n",
    "|  any     |    >10 & < 14   |         1 or 0    | for one of the arms, there is 1 placing within 10-14 sec to a moving        |    \n",
    "|  any     |    >14 & < 44   |         1         | for each arm, there is 1 placing within 10-43 sec to a moving                 \n",
    "|  any     |    >=44 & <48   |         1 or 2    | for one of the arms, there are 2 placing within 44-47 sec to a moving                |   \n",
    "|  any     |          >=48   |         2+        | for each of the arm, there are more than 2 placing within 48 or more sec to a moving                     |   \n",
    "\n",
    "The watermark does not influence the answer because, in this case, the data arrive in order and without any delay, **However it is important to clean the state**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E3.2\n",
    "\n",
    "> A continuous query that emits the events between a **pick (status==goodGrasped)** and a place (status==placingGood)\n",
    "\n",
    "NOTE: I'm adding one more type of event, good grasped that should appear before any moving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "grapsedW_sdf = (roboticArm_sdf\n",
    "                .withWatermark(\"ts\",\"1 minute\") # WATERMARK ADDED HERE\n",
    "                .where(\"status='goodGrasped'\")\n",
    "                .withColumnRenamed(\"id\",\"idGrasped\")\n",
    "                .withColumnRenamed(\"ts\",\"tsGrasped\")\n",
    "               )\n",
    "\n",
    "movingW_sdf = (roboticArm_sdf\n",
    "                .withWatermark(\"ts\",\"1 minute\") # WATERMARK ADDED HERE\n",
    "                .where(\"status='movingGood'\")\n",
    "                .withColumnRenamed(\"id\",\"idMoving\")\n",
    "                .withColumnRenamed(\"ts\",\"tsMoving\")\n",
    "               )\n",
    "\n",
    "placingW_sdf = (roboticArm_sdf\n",
    "                .withWatermark(\"ts\",\"1 minute\") # WATERMARK ADDED HERE\n",
    "                .where(\"status='placingGood'\")\n",
    "                .withColumnRenamed(\"id\",\"idPlacing\")\n",
    "                .withColumnRenamed(\"ts\",\"tsPlacing\")\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "joinGM_sdf = (grapsedW_sdf.join(\n",
    "  movingW_sdf, expr(\"\"\"\n",
    "    (idGrasped == idMoving) AND\n",
    "    (tsMoving > tsGrasped ) AND\n",
    "    (tsMoving < tsGrasped + interval 3 seconds )\"\"\" # TIME CONSTRAIN ADDED HERE (considering also that the time flows at half of the speed) !!!\n",
    "    )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- idGrasped: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- stressLevel: integer (nullable = true)\n",
      " |-- tsGrasped: timestamp (nullable = true)\n",
      " |-- idMoving: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- stressLevel: integer (nullable = true)\n",
      " |-- tsMoving: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joinGM_sdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- idPlacing: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- stressLevel: integer (nullable = true)\n",
      " |-- tsPlacing: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "placingW_sdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "joinGMP_sdf = (joinGM_sdf.join(\n",
    "  placingW_sdf, expr(\"\"\"\n",
    "    (idMoving == idPlacing) AND\n",
    "    (tsPlacing > tsMoving ) AND\n",
    "    (tsPlacing < tsMoving + interval 14 seconds )\"\"\" # TIME CONSTRAIN ADDED HERE (considering also that the time flows at half of the speed) !!!\n",
    "    )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "e3_2 = (joinGMP_sdf\n",
    "                     .writeStream\n",
    "                     .format(\"memory\")\n",
    "                     .queryName(\"sinkTable\")\n",
    "                     .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-----------+-------------------+--------+----------+-----------+-------------------+---------+-----------+-----------+-------------------+\n",
      "|idGrasped|status     |stressLevel|tsGrasped          |idMoving|status    |stressLevel|tsMoving           |idPlacing|status     |stressLevel|tsPlacing          |\n",
      "+---------+-----------+-----------+-------------------+--------+----------+-----------+-------------------+---------+-----------+-----------+-------------------+\n",
      "|2        |goodGrasped|5          |2022-11-01 15:06:01|2       |movingGood|9          |2022-11-01 15:06:02|2        |placingGood|3          |2022-11-01 15:06:12|\n",
      "|1        |goodGrasped|1          |2022-11-01 15:05:57|1       |movingGood|7          |2022-11-01 15:05:59|1        |placingGood|3          |2022-11-01 15:06:12|\n",
      "|2        |goodGrasped|5          |2022-11-01 15:05:27|2       |movingGood|9          |2022-11-01 15:05:29|2        |placingGood|3          |2022-11-01 15:05:39|\n",
      "|2        |goodGrasped|5          |2022-11-01 15:04:54|2       |movingGood|9          |2022-11-01 15:04:55|2        |placingGood|3          |2022-11-01 15:05:05|\n",
      "|1        |goodGrasped|1          |2022-11-01 15:04:50|1       |movingGood|7          |2022-11-01 15:04:52|1        |placingGood|3          |2022-11-01 15:05:05|\n",
      "|2        |goodGrasped|5          |2022-11-01 15:04:21|2       |movingGood|9          |2022-11-01 15:04:22|2        |placingGood|3          |2022-11-01 15:04:32|\n",
      "|1        |goodGrasped|1          |2022-11-01 15:04:17|1       |movingGood|7          |2022-11-01 15:04:19|1        |placingGood|3          |2022-11-01 15:04:32|\n",
      "|2        |goodGrasped|5          |2022-11-01 15:03:48|2       |movingGood|9          |2022-11-01 15:03:49|2        |placingGood|3          |2022-11-01 15:03:59|\n",
      "|1        |goodGrasped|1          |2022-11-01 15:03:44|1       |movingGood|7          |2022-11-01 15:03:46|1        |placingGood|3          |2022-11-01 15:03:59|\n",
      "|2        |goodGrasped|5          |2022-11-01 15:03:15|2       |movingGood|9          |2022-11-01 15:03:16|2        |placingGood|3          |2022-11-01 15:03:26|\n",
      "|1        |goodGrasped|1          |2022-11-01 15:03:11|1       |movingGood|7          |2022-11-01 15:03:13|1        |placingGood|3          |2022-11-01 15:03:26|\n",
      "|2        |goodGrasped|5          |2022-11-01 15:02:42|2       |movingGood|9          |2022-11-01 15:02:43|2        |placingGood|3          |2022-11-01 15:02:53|\n",
      "|1        |goodGrasped|1          |2022-11-01 15:02:38|1       |movingGood|7          |2022-11-01 15:02:40|1        |placingGood|3          |2022-11-01 15:02:53|\n",
      "|2        |goodGrasped|5          |2022-11-01 15:02:09|2       |movingGood|9          |2022-11-01 15:02:10|2        |placingGood|3          |2022-11-01 15:02:20|\n",
      "|1        |goodGrasped|1          |2022-11-01 15:02:05|1       |movingGood|7          |2022-11-01 15:02:07|1        |placingGood|3          |2022-11-01 15:02:20|\n",
      "|2        |goodGrasped|5          |2022-11-01 15:01:35|2       |movingGood|9          |2022-11-01 15:01:36|2        |placingGood|3          |2022-11-01 15:01:46|\n",
      "|1        |goodGrasped|1          |2022-11-01 15:01:31|1       |movingGood|7          |2022-11-01 15:01:33|1        |placingGood|3          |2022-11-01 15:01:46|\n",
      "|2        |goodGrasped|5          |2022-11-01 15:01:02|2       |movingGood|9          |2022-11-01 15:01:03|2        |placingGood|3          |2022-11-01 15:01:13|\n",
      "|1        |goodGrasped|1          |2022-11-01 15:00:58|1       |movingGood|7          |2022-11-01 15:01:00|1        |placingGood|3          |2022-11-01 15:01:13|\n",
      "|2        |goodGrasped|5          |2022-11-01 15:00:29|2       |movingGood|9          |2022-11-01 15:00:30|2        |placingGood|3          |2022-11-01 15:00:40|\n",
      "+---------+-----------+-----------+-------------------+--------+----------+-----------+-------------------+---------+-----------+-----------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM sinkTable ORDER BY tsGrasped DESC\").show(20,False) # note, I change ts in tsTemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "e3_2.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E3.3\n",
    "\n",
    "> A continuous query that emits **the average stress level** between a pick (status==goodGrasped) and a place (status==placingGood)\n",
    "\n",
    "NOTE: the original question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "grapsedFinal_sdf = (roboticArm_sdf\n",
    "                .withWatermark(\"ts\",\"1 minute\") # WATERMARK ADDED HERE\n",
    "                .where(\"status='goodGrasped'\")\n",
    "                .withColumnRenamed(\"stressLevel\",\"stressLevelGrasped\")\n",
    "                .withColumnRenamed(\"id\",\"idGrasped\")\n",
    "                .withColumnRenamed(\"ts\",\"tsGrasped\")\n",
    "               )\n",
    "\n",
    "movingFinal_sdf = (roboticArm_sdf\n",
    "                .withWatermark(\"ts\",\"1 minute\") # WATERMARK ADDED HERE\n",
    "                .where(\"status='movingGood'\")\n",
    "                .withColumnRenamed(\"stressLevel\",\"stressLevelMoving\")\n",
    "                .withColumnRenamed(\"id\",\"idMoving\")\n",
    "                .withColumnRenamed(\"ts\",\"tsMoving\")\n",
    "               )\n",
    "\n",
    "placingFinal_sdf = (roboticArm_sdf\n",
    "                .withWatermark(\"ts\",\"1 minute\") # WATERMARK ADDED HERE\n",
    "                .where(\"status='placingGood'\")\n",
    "                .withColumnRenamed(\"stressLevel\",\"stressLevelPlacing\")\n",
    "                .withColumnRenamed(\"id\",\"idPlacing\")\n",
    "                .withColumnRenamed(\"ts\",\"tsPlacing\")\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- idPlacing: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- stressLevelPlacing: integer (nullable = true)\n",
      " |-- tsPlacing: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "placingFinal_sdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "joinFinal_sdf = (grapsedFinal_sdf.join(\n",
    "  movingFinal_sdf, expr(\"\"\"\n",
    "    (idGrasped == idMoving) AND\n",
    "    (tsMoving > tsGrasped ) AND\n",
    "    (tsMoving < tsGrasped + interval 3 seconds )\"\"\" \n",
    "    )).join(\n",
    "  placingFinal_sdf, expr(\"\"\"\n",
    "    (idMoving == idPlacing) AND\n",
    "    (tsPlacing > tsMoving ) AND\n",
    "    (tsPlacing < tsMoving + interval 14 seconds )\"\"\"\n",
    "    ))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- idGrasped: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- stressLevelGrasped: integer (nullable = true)\n",
      " |-- tsGrasped: timestamp (nullable = true)\n",
      " |-- idMoving: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- stressLevelMoving: integer (nullable = true)\n",
      " |-- tsMoving: timestamp (nullable = true)\n",
      " |-- idPlacing: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- stressLevelPlacing: integer (nullable = true)\n",
      " |-- tsPlacing: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joinFinal_sdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sdf = joinFinal_sdf.select(col(\"idGrasped\").alias(\"id\"), expr(\"(stressLevelGrasped+stressLevelMoving+stressLevelPlacing)/3 AS AVG_stressLevel\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "e3_3 = (final_sdf\n",
    "                     .writeStream\n",
    "                     .format(\"memory\")\n",
    "                     .queryName(\"sinkTable\")\n",
    "                     .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+\n",
      "|id |AVG_stressLevel   |\n",
      "+---+------------------+\n",
      "|1  |3.6666666666666665|\n",
      "|1  |3.6666666666666665|\n",
      "|1  |3.6666666666666665|\n",
      "|1  |3.6666666666666665|\n",
      "|1  |3.6666666666666665|\n",
      "|1  |3.6666666666666665|\n",
      "|1  |3.6666666666666665|\n",
      "|1  |3.6666666666666665|\n",
      "|1  |3.6666666666666665|\n",
      "|1  |3.6666666666666665|\n",
      "|1  |3.6666666666666665|\n",
      "|1  |3.6666666666666665|\n",
      "|1  |3.6666666666666665|\n",
      "|1  |3.6666666666666665|\n",
      "|1  |3.6666666666666665|\n",
      "|1  |3.6666666666666665|\n",
      "|1  |3.6666666666666665|\n",
      "|2  |5.666666666666667 |\n",
      "|2  |5.666666666666667 |\n",
      "|2  |5.666666666666667 |\n",
      "+---+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM sinkTable\").show(20,False) # note, I change ts in tsTemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "e3_3.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Think out of the box!!!\n",
    "\n",
    "**Is the complexity of temporal joins acceptable? Is there any other solution that does not require them?**\n",
    "\n",
    "In many cases, query answering is hard because the datamodel is **over simplified**.\n",
    "\n",
    "We may go back to E1 problem and propose to change the model so to eliminate the need for a temporal join. A sequential number for the cycles of each arm would be enough to make the join deterministic. See [datagen2.ipynb](datagen1.ipynb) for the changes in the data generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- cycle: integer (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- stressLevel: integer (nullable = true)\n",
      " |-- ts: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "roboticArmV2_schema = StructType([             ## <-- CHANGE HERE new name for the schema\n",
    "    StructField(\"id\", StringType(), True),\n",
    "    StructField(\"cycle\", IntegerType(), True), ## <-- CHANGE HERE new field \n",
    "    StructField(\"status\", StringType(), True),\n",
    "    StructField(\"stressLevel\", IntegerType(), True),\n",
    "    StructField(\"ts\", TimestampType(), True)])\n",
    "\n",
    "raw_roboticArmV2_df = (spark                   ## <-- CHANGE HERE new name for the df\n",
    "  .readStream\n",
    "  .format(\"kafka\")\n",
    "  .option(\"kafka.bootstrap.servers\", servers)\n",
    "  .option(\"startingOffsets\", \"earliest\")\n",
    "  .option(\"subscribe\", \"RoboticArmV2\") ## <-- CHANGE HERE different topic\n",
    "  .load())\n",
    "\n",
    "roboticArmV2_sdf = (raw_roboticArmV2_df      ## <-- CHANGE HERE new name sdf\n",
    "                      .select(from_json(col(\"value\").cast(\"string\"), roboticArmV2_schema).alias(\"value\")) ## <-- CHANGE HERE new schema\n",
    "                      .select(\"value.*\"))\n",
    "\n",
    "roboticArmV2_sdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "grapsedFinalCyc_sdf = (roboticArmV2_sdf\n",
    "                .withWatermark(\"ts\",\"1 minute\") \n",
    "                .where(\"status='goodGrasped'\")\n",
    "                .withColumnRenamed(\"stressLevel\",\"stressLevelGrasped\")\n",
    "                .withColumnRenamed(\"id\",\"idGrasped\")\n",
    "                .withColumnRenamed(\"cycle\",\"cycleGrasped\")\n",
    "               )\n",
    "\n",
    "movingFinalCyc_sdf = (roboticArmV2_sdf\n",
    "                .withWatermark(\"ts\",\"1 minute\") \n",
    "                .where(\"status='movingGood'\")\n",
    "                .withColumnRenamed(\"stressLevel\",\"stressLevelMoving\")\n",
    "                .withColumnRenamed(\"id\",\"idMoving\")\n",
    "                .withColumnRenamed(\"cycle\",\"cycleMoving\")\n",
    "               )\n",
    "\n",
    "placingFinalCyc_sdf = (roboticArmV2_sdf\n",
    "                .withWatermark(\"ts\",\"1 minute\") \n",
    "                .where(\"status='placingGood'\")\n",
    "                .withColumnRenamed(\"stressLevel\",\"stressLevelPlacing\")\n",
    "                .withColumnRenamed(\"id\",\"idPlacing\")\n",
    "                .withColumnRenamed(\"cycle\",\"cyclePlacing\")\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "joinFinalCyc_sdf = (grapsedFinalCyc_sdf.join(\n",
    "  movingFinalCyc_sdf, expr(\"\"\"\n",
    "    (idGrasped == idMoving) AND\n",
    "    (cycleGrasped == cycleMoving )\"\"\" ## <- CHANGE HERE  \n",
    "    )).join(\n",
    "  placingFinalCyc_sdf, expr(\"\"\"\n",
    "    (idMoving == idPlacing) AND\n",
    "    (cycleMoving == cyclePlacing)\"\"\" ## <- CHANGE HERE \n",
    "    ))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joinV2_sdf = (movingV2_sdf.join(\n",
    "  placingV2_sdf, expr(\"\"\"\n",
    "    (idMoving == idPlacing) AND\n",
    "    (cyclePlacing == cycleMoving )\"\"\" ## <- CHANGE HERE \n",
    "    )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalCyc_sdf = joinFinalCyc_sdf.select(col(\"idGrasped\").alias(\"id\"), expr(\"(stressLevelGrasped+stressLevelMoving+stressLevelPlacing)/3 AS AVG_stressLevel\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "e3V2 = (finalCyc_sdf\n",
    "                     .writeStream\n",
    "                     .format(\"memory\")\n",
    "                     .queryName(\"sinkTable\")\n",
    "                     .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+\n",
      "|id |AVG_stressLevel   |\n",
      "+---+------------------+\n",
      "|2  |5.666666666666667 |\n",
      "|1  |3.6666666666666665|\n",
      "|1  |3.6666666666666665|\n",
      "|2  |5.666666666666667 |\n",
      "|1  |3.6666666666666665|\n",
      "|2  |5.666666666666667 |\n",
      "|1  |3.6666666666666665|\n",
      "|2  |5.666666666666667 |\n",
      "|1  |3.6666666666666665|\n",
      "|1  |3.6666666666666665|\n",
      "|1  |3.6666666666666665|\n",
      "|2  |5.666666666666667 |\n",
      "|1  |3.6666666666666665|\n",
      "|2  |5.666666666666667 |\n",
      "|1  |3.6666666666666665|\n",
      "|2  |5.666666666666667 |\n",
      "|2  |5.666666666666667 |\n",
      "|2  |5.666666666666667 |\n",
      "|1  |3.6666666666666665|\n",
      "|2  |5.666666666666667 |\n",
      "+---+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM sinkTable\").show(20,False) # note, I change ts in tsTemp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Much easier** !!\n",
    "\n",
    "**REMEMBER**: modeling and querying are *two sides of the same coin*\n",
    "\n",
    "We are not in a traditional RDBMS where modeling is done once for all by the DB administrator and queries must conform to \"the model\". We are in a setting where performance matters more than governance and chaning the model is often the only way to keep good performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "e3V2.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E4\n",
    "\n",
    ">A continuous query that returns the robotic arms that,\n",
    ">\n",
    "> * in less than 20 second (was 10 in EPL, but here the time passes at half of the speed),\n",
    "> * picked a good while safely operating,\n",
    "> * moved it while the controller was raising a warning, and\n",
    "> * placed it while safely operating again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodGraspedSafely_sdf = (roboticArmV2_sdf\n",
    "                .withWatermark(\"ts\",\"1 minute\")\n",
    "                .where(\"status='goodGrasped' AND stressLevel < 7\")\n",
    "                .withColumnRenamed(\"id\",\"idGrasped\")\n",
    "                .withColumnRenamed(\"cycle\",\"cycleGrasped\")\n",
    "                .withColumnRenamed(\"stressLevel\",\"stressLevelGrasped\")\n",
    "                .withColumnRenamed(\"ts\",\"tsGrasped\")\n",
    "               )\n",
    "\n",
    "movingWarning_sdf = (roboticArmV2_sdf\n",
    "                .withWatermark(\"ts\",\"1 minute\")\n",
    "                .where(\"status='movingGood' AND stressLevel > 6 AND stressLevel < 9\")\n",
    "                .withColumnRenamed(\"id\",\"idMoving\")\n",
    "                .withColumnRenamed(\"cycle\",\"cycleMoving\")\n",
    "                .withColumnRenamed(\"stressLevel\",\"stressLevelMoving\")\n",
    "                .withColumnRenamed(\"ts\",\"tsMoving\")\n",
    "               )\n",
    "\n",
    "placingSafely_sdf = (roboticArmV2_sdf\n",
    "                .withWatermark(\"ts\",\"1 minute\")\n",
    "                .where(\"status='placingGood' AND stressLevel < 7\")\n",
    "                .withColumnRenamed(\"id\",\"idPlacing\")\n",
    "                .withColumnRenamed(\"cycle\",\"cyclePlacing\")\n",
    "                .withColumnRenamed(\"stressLevel\",\"stressLevelPlacing\")\n",
    "                .withColumnRenamed(\"ts\",\"tsPlacing\")\n",
    "               )\n",
    "\n",
    "join1_sdf = (goodGraspedSafely_sdf.join(\n",
    "    movingWarning_sdf, expr(\"\"\"\n",
    "    (idGrasped == idMoving) AND\n",
    "    (cycleGrasped == cycleMoving)\"\"\" \n",
    "    )))\n",
    "\n",
    "join2_sdf = (join1_sdf.join(\n",
    "  placingSafely_sdf, expr(\"\"\"\n",
    "    (idMoving == idPlacing) AND\n",
    "    (cyclePlacing == cycleMoving )\"\"\" \n",
    "    )))\n",
    "\n",
    "within20sec = join2_sdf.where(\"tsPlacing <= tsGrasped + interval 20 seconds\")\n",
    "\n",
    "e4 = (within20sec\n",
    "                     .writeStream\n",
    "                     .format(\"memory\")\n",
    "                     .queryName(\"sinkTable\")\n",
    "                     .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|ID |cycle|\n",
      "+---+-----+\n",
      "|1  |24   |\n",
      "|1  |23   |\n",
      "|1  |22   |\n",
      "|1  |21   |\n",
      "|1  |20   |\n",
      "+---+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT idGrasped AS ID, cyclePlacing AS cycle FROM sinkTable ORDER BY cyclePlacing DESC\").show(5,False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "indeed only the arm whose ID is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "e4.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E5\n",
    "\n",
    "> A continuous query that monitors the results of the previous one (i.e., E4) and counts how many times each robotic arm is present in the stream over a window of 20 seconds updating the counting every 4 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- idGrasped: string (nullable = true)\n",
      " |-- cycleGrasped: integer (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- stressLevelGrasped: integer (nullable = true)\n",
      " |-- tsGrasped: timestamp (nullable = true)\n",
      " |-- idMoving: string (nullable = true)\n",
      " |-- cycleMoving: integer (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- stressLevelMoving: integer (nullable = true)\n",
      " |-- tsMoving: timestamp (nullable = true)\n",
      " |-- idPlacing: string (nullable = true)\n",
      " |-- cyclePlacing: integer (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- stressLevelPlacing: integer (nullable = true)\n",
      " |-- tsPlacing: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "within20sec.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "e5 = (within20sec\n",
    "                     .withWatermark(\"tsPlacing\", \"1 minutes\")\n",
    "                     .groupBy(window(\"tsPlacing\", \"40 seconds\", \"8 seconds\"),\"idGrasped\")\n",
    "                     .count()\n",
    "                     .writeStream\n",
    "                     .format(\"memory\")\n",
    "                     .queryName(\"sinkTable\") \n",
    "                     .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+---------+-----+\n",
      "|window                                    |idGrasped|count|\n",
      "+------------------------------------------+---------+-----+\n",
      "|[2021-10-28 14:00:40, 2021-10-28 14:01:20]|1        |1    |\n",
      "|[2021-10-28 14:00:32, 2021-10-28 14:01:12]|1        |1    |\n",
      "|[2021-10-28 14:00:24, 2021-10-28 14:01:04]|1        |2    |\n",
      "|[2021-10-28 14:00:16, 2021-10-28 14:00:56]|1        |1    |\n",
      "|[2021-10-28 14:00:08, 2021-10-28 14:00:48]|1        |1    |\n",
      "|[2021-10-28 14:00:00, 2021-10-28 14:00:40]|1        |1    |\n",
      "|[2021-10-28 13:59:52, 2021-10-28 14:00:32]|1        |2    |\n",
      "|[2021-10-28 13:59:44, 2021-10-28 14:00:24]|1        |1    |\n",
      "|[2021-10-28 13:59:36, 2021-10-28 14:00:16]|1        |1    |\n",
      "|[2021-10-28 13:59:28, 2021-10-28 14:00:08]|1        |1    |\n",
      "+------------------------------------------+---------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM sinkTable ORDER BY window DESC\").show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "e5.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
